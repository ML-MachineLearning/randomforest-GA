{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import datacube\n",
    "import fiona\n",
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_invalid_data\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.geometry import CRS\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import gdal\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import shape\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Set up datacube instance\n",
    "dc = datacube.Datacube(app = 'Random forest classification')\n",
    "\n",
    "\n",
    "def load_nbart(sensor, query):\n",
    "    \n",
    "    '''\n",
    "    Loads nbart data for a sensor, mask by pq and filter terrain -999s.\n",
    "    Modified from original function written by B Dunn (2017).\n",
    "    \n",
    "    :attr sensor: Landsat sensor to import (valid options: 'ls5', 'ls7', 'ls8')\n",
    "    :attr query: complete datacube query used to import data\n",
    "    \n",
    "    :returns: xarray dataset matching query\n",
    "    '''  \n",
    "    \n",
    "    product_name = '{}_{}_albers'.format(sensor, 'nbart')\n",
    "    print('Loading {}'.format(product_name))\n",
    "    ds = dc.load(product = product_name,\n",
    "                 group_by = 'solar_day', \n",
    "                 **query)\n",
    "    \n",
    "    if ds:       \n",
    "   \n",
    "        print('Loaded {}'.format(product_name))\n",
    "        \n",
    "        # Extract PQ data for masking\n",
    "        mask_product = '{}_{}_albers'.format(sensor, 'pq')\n",
    "        sensor_pq = dc.load(product = mask_product, \n",
    "                            fuse_func = ga_pq_fuser,\n",
    "                            group_by = 'solar_day', \n",
    "                            **query)\n",
    "        \n",
    "        if sensor_pq:\n",
    "            \n",
    "            print('Making mask {}'.format(mask_product))\n",
    "            cloud_free = masking.make_mask(sensor_pq.pixelquality,\n",
    "                                           cloud_acca = 'no_cloud',\n",
    "                                           cloud_shadow_acca = 'no_cloud_shadow',                           \n",
    "                                           cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                                           cloud_fmask = 'no_cloud',\n",
    "                                           blue_saturated = False,\n",
    "                                           green_saturated = False,\n",
    "                                           red_saturated = False,\n",
    "                                           nir_saturated = False,\n",
    "                                           swir1_saturated = False,\n",
    "                                           swir2_saturated = False,\n",
    "                                           contiguous = True)\n",
    "            \n",
    "            # Filter to remove clouds and -999 terrain issues\n",
    "            ds = ds.where(cloud_free)\n",
    "            ds = ds.where(ds != -999.0)\n",
    "            \n",
    "            # Add projection attributes\n",
    "            ds.attrs['crs'] = ds.crs\n",
    "            ds.attrs['affine'] = ds.affine    \n",
    "            ds.attrs['geo_transform'] = ds.geobox.transform.to_gdal()\n",
    "            ds.attrs['proj'] = ds.geobox.crs.wkt\n",
    "            print('Masked {} with {} and filtered ' \\\n",
    "                  'terrain'.format(product_name, mask_product))\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            print('Did not mask {} with {}'.format(product_name, mask_product))\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        print ('Did not load {}'.format(product_name)) \n",
    "\n",
    "    if len(ds) > 0:\n",
    "        \n",
    "        return ds\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "def rasterize_vector(input_data, cols, rows, geo_transform,\n",
    "                     projection, field):\n",
    "    \n",
    "    \"\"\"\n",
    "    Rasterize a vector file and return numpy array\n",
    "    \n",
    "    :attr input_data: input shapefile path or preloaded GDAL/OGR layer\n",
    "    :attr cols: width of output array in columns\n",
    "    :attr rows: height of output array in rows\n",
    "    :attr geo_transform: geotransform for rasterization\n",
    "    :attr projection: projection for rasterization\n",
    "    :attr field: shapefile field to take values from\n",
    "    \n",
    "    :returns: a 'row x col' array containg values from vector\n",
    "    \"\"\"\n",
    "    \n",
    "    # If input data is a string, import as shapefile layer\n",
    "    if isinstance(input_data, str):    \n",
    "    \n",
    "        # Open vector with gdal\n",
    "        data_source = gdal.OpenEx(vector_data_path, gdal.OF_VECTOR)\n",
    "        input_data = data_source.GetLayer(0)\n",
    "    \n",
    "    # Set up output raster\n",
    "    driver = gdal.GetDriverByName('MEM')  # In memory dataset\n",
    "    target_ds = driver.Create('', cols, rows, 1, gdal.GDT_UInt16)\n",
    "    target_ds.SetGeoTransform(geo_transform)\n",
    "    target_ds.SetProjection(projection)\n",
    "    \n",
    "    # Rasterize shapefile and extract array\n",
    "    gdal.RasterizeLayer(target_ds, [1], input_data, options=[\"ATTRIBUTE=\" + field])\n",
    "    band = target_ds.GetRasterBand(1)\n",
    "    out_array = band.ReadAsArray()\n",
    "    target_ds = None\n",
    "    \n",
    "    return out_array\n",
    "\n",
    "\n",
    "def write_geotiff(fname, data, geo_transform, projection, nodata_val):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a single band GeoTIFF file with data from array.\n",
    "    \n",
    "    :attr fname: output file path\n",
    "    :attr data: input array\n",
    "    :attr geo_transform: geotransform for output raster\n",
    "    :attr projection: projection for output raster\n",
    "    :attr nodata_val: value to convert to nodata in output raster\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up driver\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    \n",
    "    # Create raster of given size and projection\n",
    "    rows, cols = data.shape\n",
    "    dataset = driver.Create(fname, cols, rows, 1, gdal.GDT_Byte)\n",
    "    dataset.SetGeoTransform(geo_transform)\n",
    "    dataset.SetProjection(projection)\n",
    "    \n",
    "    # Write data to array and set nodata values\n",
    "    band = dataset.GetRasterBand(1)\n",
    "    band.WriteArray(data)\n",
    "    band.SetNoDataValue(nodata_val)\n",
    "    \n",
    "    # Close file\n",
    "    dataset = None     \n",
    "    \n",
    "\n",
    "def tasseled_cap(sensor_data, sensor, tc_bands = ['greenness', 'brightness', 'wetness'], \n",
    "                 drop = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes tasseled cap wetness, greenness and brightness bands from a six\n",
    "    band xarray dataset, and returns a new xarray dataset with old bands \n",
    "    optionally dropped\n",
    "    \n",
    "    :attr sensor_data: input xarray dataset with six Landsat bands\n",
    "    :attr tc_bands: list of tasseled cap bands to compute \n",
    "    (valid options: 'wetness', 'greenness','brightness'\n",
    "    :attr sensor: Landsat sensor used for coefficient values \n",
    "    (valid options: 'ls5', 'ls7', 'ls8')\n",
    "    :attr drop: if 'drop = False', return all original Landsat bands \n",
    "    \n",
    "    :returns: xarray dataset with newly computed tasseled cap bands\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy input dataset\n",
    "    output_array = sensor_data.copy(deep = True)\n",
    " \n",
    "    # Coefficients for each tasseled cap band\n",
    "    wetness_coeff = {'ls5':{'blue':0.0315, 'green':0.2021, 'red':0.3102, \n",
    "                            'nir':0.1594, 'swir1':-0.6806, 'swir2':-0.6109},\n",
    "                     'ls7':{'blue':0.0315, 'green':0.2021, 'red':0.3102, \n",
    "                            'nir':0.1594, 'swir1':-0.6806, 'swir2':-0.6109},\n",
    "                     'ls8':{'blue':0.0315, 'green':0.2021, 'red':0.3102, \n",
    "                            'nir':0.1594, 'swir1':-0.6806, 'swir2':-0.6109}}\n",
    "    \n",
    "    greenness_coeff = {'ls5':{'blue':-0.1603, 'green':-0.2819, 'red':-0.4934, \n",
    "                              'nir':0.7940, 'swir1':-0.0002, 'swir2':-0.1446},\n",
    "                       'ls7':{'blue':-0.1603, 'green':-0.2819, 'red':-0.4934, \n",
    "                              'nir':0.7940, 'swir1':-0.0002, 'swir2':-0.1446},\n",
    "                       'ls8':{'blue':-0.1603, 'green':-0.2819, 'red':-0.4934, \n",
    "                              'nir':0.7940, 'swir1':-0.0002, 'swir2':-0.1446}}\n",
    "    \n",
    "    brightness_coeff = {'ls5':{'blue':0.2043, 'green':0.4158, 'red':0.5524, \n",
    "                               'nir':0.5741, 'swir1':0.3124, 'swir2':0.2303},\n",
    "                        'ls7':{'blue':0.2043, 'green':0.4158, 'red':0.5524, \n",
    "                               'nir':0.5741, 'swir1':0.3124, 'swir2':0.2303},\n",
    "                        'ls8':{'blue':0.2043, 'green':0.4158, 'red':0.5524, \n",
    "                               'nir':0.5741, 'swir1':0.3124, 'swir2':0.2303}}\n",
    "    \n",
    "    # Dict to use correct coefficients for each tasseled cap band\n",
    "    analysis_coefficient = {'wetness': wetness_coeff, \n",
    "                            'greenness': greenness_coeff,\n",
    "                            'brightness': brightness_coeff}\n",
    "    \n",
    "    # For each band, compute tasseled cap band and add to output dataset\n",
    "    for tc_band in tc_bands:\n",
    "\n",
    "        # Create xarray of coefficient values used to multiply each band of input\n",
    "        coeff = xr.Dataset(analysis_coefficient[tc_band][sensor])    \n",
    "        sensor_coeff = sensor_data * coeff\n",
    "\n",
    "        # Sum all bands\n",
    "        output_array[tc_band] = sensor_coeff.blue + sensor_coeff.green + \\\n",
    "                                sensor_coeff.red + sensor_coeff.nir + \\\n",
    "                                sensor_coeff.swir1 + sensor_coeff.swir2\n",
    "    \n",
    "    # If drop = True, remove original bands\n",
    "    if drop:\n",
    "        \n",
    "        bands_to_drop = list(sensor_data.data_vars)        \n",
    "        output_array = output_array.drop(bands_to_drop)        \n",
    "\n",
    "    return(output_array)\n",
    "\n",
    "\n",
    "def point_in_poly(lon, lat, field, shapefile):\n",
    "    \n",
    "    \"\"\"\n",
    "    Extract data from polygon that contains point\n",
    "    \n",
    "    :attr lon: x coordinate of point\n",
    "    :attr lat: y coordinate of point\n",
    "    :attr field: field of polygon shapefile to extract for matching points\n",
    "    :attr shapefile: polygon shapefile to import\n",
    "    \n",
    "    :returns: if point falls within polygon, return field from polygon\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert coordinates to shapely point\n",
    "    mypoint = Point(lon, lat)   \n",
    "\n",
    "    # Extract polygon info\n",
    "    with fiona.open(shapefile) as shp:\n",
    "\n",
    "        # For each polygon, identify if point falls within polygon\n",
    "        poly_idx = [poly['properties'][field] for i, poly in enumerate(shp)\n",
    "                    if mypoint.within(shape(poly['geometry']))]\n",
    "\n",
    "    # If point is within polygon\n",
    "    if poly_idx:\n",
    "        \n",
    "        # Take first polygon to avoid multiple matches        \n",
    "        return(poly_idx[0])\n",
    "\n",
    "    # If point not found in any polygon, return none\n",
    "    else: \n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "def layer_extent(layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes min and max extents for GDAL layer features. Compared to\n",
    "    built-in \".GetExtent\" that always returns unfiltered extents, this \n",
    "    allows you to compute extents of features within filtered layers \n",
    "    (e.g. layers filtered with 'SetAttributeFilter')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract tuples of x, y, z coordinates for each point feature\n",
    "    point_coords = [feature.geometry().GetPoint() for feature in layer]\n",
    "    \n",
    "    # Compute mins and maxes across points for each tuple element\n",
    "    max_x, max_y, max_z = map(min, zip(*point_coords))\n",
    "    min_x, min_y, min_z = map(max, zip(*point_coords))    \n",
    "    \n",
    "    return  min_x, max_x, min_y, max_y\n",
    "\n",
    "\n",
    "def randomforest_train(train_shps, train_field, data_func, \n",
    "                       data_func_params = {}, classifier_params = {}):\n",
    "    \n",
    "    '''\n",
    "    Extracts training data from xarray dataset for multiple training shapefiles.\n",
    "    Loops through each each training shapefile, calling dc.load on extent of file.\n",
    "    \n",
    "    :attr train_shps: list of training shapefile paths to import. Each file \n",
    "    should cover a small enough spatial area so as to not slow dc.load function \n",
    "    excessively (e.g. 100 x 100km max)\n",
    "    :attr train_field: shapefile field containing classification class\n",
    "    :attr data_func: function to import xarray data for each shapefile. Should return \n",
    "    an xarray dataset with 'geo_transform' and 'proj' attributes\n",
    "    :attr data_func_params: dict of optional dc.load query inputs. Useful for defining \n",
    "    time query for temporal datasets (spatial queries are set automatically from shapefiles)\n",
    "    :attr classifier_params: dict of optional parameters for training random forest\n",
    "    \n",
    "    :returns: trained classifier\n",
    "    :returns: array of training labels\n",
    "    :returns: array of training data\n",
    "    '''\n",
    "\n",
    "    # Output training label and pixel arrays\n",
    "    training_labels_list = list()\n",
    "    training_samples_list = list()\n",
    "\n",
    "    # For each shapefile, extract datacube data using extent of points\n",
    "    # and add resulting spectral data and labels to list of arrays\n",
    "    for train_shp in train_shps:\n",
    "\n",
    "        print(\"Importing training data from {} using query:\".format(train_shp))\n",
    "\n",
    "        # Open vector of training points with gdal\n",
    "        data_source = gdal.OpenEx(train_shp, gdal.OF_VECTOR)\n",
    "        layer = data_source.GetLayer(0)      \n",
    "\n",
    "        # Compute extents and generate spatial query\n",
    "        xmin, xmax, ymin, ymax = layer_extent(layer) \n",
    "        query_train = {'x': (xmin + 500, xmax - 500),\n",
    "                       'y': (ymin + 500, ymax - 500),\n",
    "                       'crs': 'EPSG:3577',\n",
    "                       **data_func_params}        \n",
    "        print(query_train)\n",
    "\n",
    "        # Import data  as xarray and extract projection/transform data\n",
    "        training_xarray = data_func(query_train)\n",
    "        geo_transform_train = training_xarray.geo_transform\n",
    "        proj_train = training_xarray.proj \n",
    "\n",
    "        # Covert to array and rearrange dimension order\n",
    "        bands_array_train = training_xarray.to_array().values\n",
    "        bands_array_train = np.einsum('bxy->xyb', bands_array_train)\n",
    "        rows_train, cols_train, bands_n_train = bands_array_train.shape\n",
    "\n",
    "        # Import training data shapefiles and convert to matching raster pixels\n",
    "        training_shapefile = train_shp\n",
    "        training_pixels = rasterize_vector(layer, cols_train, rows_train, \n",
    "                                           geo_transform_train, proj_train, \n",
    "                                           field = train_field)  \n",
    "\n",
    "        # Extract matching image sample data for each labelled pixel location\n",
    "        is_train = np.nonzero(training_pixels)\n",
    "        training_labels = training_pixels[is_train]\n",
    "        training_samples = bands_array_train[is_train]\n",
    "\n",
    "        # Remove nans from training samples\n",
    "        training_labels = training_labels[~np.isnan(training_samples).any(axis=1)]\n",
    "        training_samples = training_samples[~np.isnan(training_samples).any(axis=1)]\n",
    "\n",
    "        # Append outputs\n",
    "        training_labels_list.append(training_labels)\n",
    "        training_samples_list.append(training_samples)\n",
    "\n",
    "    # Combine polygon training data    \n",
    "    training_labels = np.concatenate(training_labels_list, axis=0)\n",
    "    training_samples = np.concatenate(training_samples_list, axis=0)  \n",
    "\n",
    "    # Set up classifier and train on training sample data and labels\n",
    "    # Options for tuning: https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "    print(\"\\nTraining random forest classifier...\")\n",
    "    classifier = RandomForestClassifier(**classifier_params) \n",
    "    classifier.fit(training_samples, training_labels)\n",
    "    print(\"Model trained on {0} bands and \"\n",
    "          \"{1} training samples\".format(training_samples.shape[1],\n",
    "                                        str(len(training_samples))))\n",
    "    \n",
    "    return classifier, training_labels, training_samples\n",
    "\n",
    "\n",
    "def randomforest_classify(classifier, analysis_data, classification_output):\n",
    "    \n",
    "    '''\n",
    "    Performs classification of xarray dataset using pre-trained random forest \n",
    "    classifier, and export classified output to a geotiff\n",
    "    \n",
    "    :attr classifier: random forest classifier generated using randomforest_train\n",
    "    :attr analysis_data: xarray dataset with 'geo_transform' and 'proj' attributes\n",
    "    and the same number of bands as data used to train classifier\n",
    "    :attr classification_output: file path to output geotiff classification \n",
    "    '''\n",
    "\n",
    "    geo_transform = analysis_data.geo_transform\n",
    "    proj = analysis_data.proj \n",
    "\n",
    "    # Covert to array and rearrange dimension order\n",
    "    analysis_array = analysis_data.to_array().values\n",
    "    analysis_array = np.einsum('bxy->xyb', analysis_array)\n",
    "    rows, cols, bands_n = analysis_array.shape\n",
    "    print(\"Data to classify:\\nRows: {0}\\nColumns: {1}\\nBands: {2}\".format(rows, cols, bands_n))\n",
    "\n",
    "    # Remove nodata and return flattened 'pixel x bands' array\n",
    "    input_nodata = np.isnan(analysis_array).any(axis = 2)\n",
    "    flat_pixels = analysis_array[~input_nodata]\n",
    "\n",
    "    # Run classification\n",
    "    print(\"Classification running...\")\n",
    "    result = classifier.predict(flat_pixels)\n",
    "\n",
    "    # Restore 2D array by assigning flattened output to empty array\n",
    "    classification = np.zeros((rows, cols))\n",
    "    classification[~input_nodata] = result\n",
    "    print(\"  Classification complete\")\n",
    "\n",
    "    # Nodata removed\n",
    "    print(\"  \" + str(np.sum(classification == 0)) + \" nodata cells removed\")\n",
    "\n",
    "    # Export to file\n",
    "    write_geotiff(classification_output, \n",
    "                  data = classification, \n",
    "                  geo_transform = geo_transform, \n",
    "                  projection = proj,\n",
    "                  nodata_val = 0)\n",
    "    print(\"    Classification exported\")\n",
    "\n",
    "    \n",
    "def randomforest_eval(training_labels, training_samples, classifier_scenario, \n",
    "                      output_path, max_estimators = 100):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes a set of training labels and training samples, and plots OOB error against\n",
    "    a range of classifier parameters to explore how parameters affect classification.\n",
    "    \n",
    "    :attr training_labels: an (X, ) array of training labels\n",
    "    :attr training_samples: an (X, B) array of training sample data\n",
    "    :attr classifier_scenario: dict of classifier scenarios to plot\n",
    "    :attr output_path: output path for plot of OOB error by scenario\n",
    "    :attr max_estimators: max number of estimators to plot on x-axis (default = 100)\n",
    "    \"\"\"\n",
    "\n",
    "    # Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "    error_rate = OrderedDict((label, []) for label, _ in classifier_scenario)\n",
    "\n",
    "    # Range of `n_estimators` values to explore.\n",
    "    min_estimators = 1\n",
    "\n",
    "    for label, clf in classifier_scenario:\n",
    "        for i in range(min_estimators, max_estimators + 1):\n",
    "            clf.set_params(n_estimators = i)\n",
    "            clf.fit(train_samp, train_lab)\n",
    "\n",
    "            # Record the OOB error for each `n_estimators=i` setting.\n",
    "            oob_error = 1 - clf.oob_score_\n",
    "            error_rate[label].append((i, oob_error))\n",
    "\n",
    "    # Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "    for label, clf_err in error_rate.items():\n",
    "        xs, ys = zip(*clf_err)\n",
    "        plt.plot(xs, ys, label = label)\n",
    "\n",
    "    # Plot and save output as figure\n",
    "    plt.xlim(min_estimators, max_estimators)\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"OOB error rate\")\n",
    "    plt.legend(loc = \"upper right\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# List of training files to import. Each file should cover a small enough spatial area \n",
    "# so as to not slow dc.load function excessively (e.g. 100 x 100km max)\n",
    "train_shps = [\"raw_data/train/training_data_tasseledcap.shp\"]\n",
    "    \n",
    "# Classification output path\n",
    "classification_output = \"output_data/classification_dc_tasseledcap.tiff\"\n",
    "\n",
    "# Output class names\n",
    "# class_names = [\"mangrove\", \"water\", \"veg\", \"other\"]\n",
    "classification_names = [\"swamp\", \"escarpment\", \"plateau\", \"ephem_swamp\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used to import training and analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hltc_import(query):\n",
    "    \n",
    "    \"\"\"\n",
    "    Imports high and low composite data for a given spatial query, and\n",
    "    return an xarray dataset with 'geo_transform' and 'proj' attributes \n",
    "    \n",
    "    :attr query: spatial query for datacube.load()\n",
    "    :returns: xarray dataset with 'geo_transform' and 'proj' attributes\n",
    "    \"\"\"\n",
    "\n",
    "    # Import data\n",
    "    low_tide = dc.load(product = 'low_tide_comp_20p', **query)\n",
    "    high_tide = dc.load(product = 'high_tide_comp_20p', **query)\n",
    "\n",
    "    # Rename variables in each high/low composite so datasets can be merged\n",
    "    data_vars = list(low_tide.keys())[3:]  # select only data vars, not coords\n",
    "    low_tide.rename({var: \"lt_\" + var for var in data_vars}, inplace = True)\n",
    "    high_tide.rename({var: \"ht_\" + var for var in data_vars}, inplace = True)\n",
    "\n",
    "    # Combine into one dataset\n",
    "    output_xarray = xr.auto_combine([low_tide, high_tide]).isel(time = 0)\n",
    "    \n",
    "    # Set attributes   \n",
    "    output_xarray.attrs['proj'] = low_tide.geobox.crs.wkt\n",
    "    output_xarray.attrs['geo_transform'] = low_tide.geobox.transform.to_gdal()    \n",
    "    \n",
    "    return output_xarray\n",
    "\n",
    "\n",
    "def tc_import(query):\n",
    "    \n",
    "    '''\n",
    "    Wrapper around load_nbart and tasseled cap to return an xarray dataset with \n",
    "    'geo_transform' and 'proj' attributes\n",
    "    \n",
    "    :attr query: query for datacube call; for training, supply only\n",
    "    non-spatial queries as spatial are generated from training data\n",
    "    :returns: xarray dataset with 'geo_transform' and 'proj' attributes\n",
    "    '''\n",
    "    \n",
    "    # Import cleaned Landsat bands data\n",
    "    nbar_example = load_nbart('ls8', query)\n",
    "    \n",
    "    # Compute tasseled cap indices and take median of multiple timesteps\n",
    "    output_xarray = tasseled_cap(sensor_data = nbar_example, \n",
    "                                 sensor = 'ls8',\n",
    "                                 drop = True).median(\"time\", keep_attrs = True)\n",
    "    \n",
    "    return output_xarray        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing training data from raw_data/train/training_data_tasseledcap.shp using query:\n",
      "{'x': (352998.0302334339, 313256.0191187404), 'y': (-1317049.5107177817, -1347981.8454887671), 'crs': 'EPSG:3577', 'time': ('2017-03-01', '2017-06-28')}\n",
      "Loading ls8_nbart_albers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:47: FutureWarning: casting an xarray.Dataset to a boolean will change in xarray v0.11 to only include data variables, not coordinates. Cast the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ls8_nbart_albers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:58: FutureWarning: casting an xarray.Dataset to a boolean will change in xarray v0.11 to only include data variables, not coordinates. Cast the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making mask ls8_pq_albers\n",
      "Masked ls8_nbart_albers with ls8_pq_albers and filtered terrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:93: FutureWarning: calling len() on an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Call len() on the Dataset.variables property instead, like ``len(ds.variables)``, to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training random forest classifier...\n",
      "Model trained on 3 bands and 71 training samples\n"
     ]
    }
   ],
   "source": [
    "# Dict of classifier parameters\n",
    "classifier_params = {'n_jobs': -1,                                    \n",
    "                     'n_estimators': 100,\n",
    "                     'max_features': \"auto\",\n",
    "                     'min_samples_leaf': 3,\n",
    "                     'oob_score': True }\n",
    "\n",
    "# Optional time query parameters (used for temporal datasets)\n",
    "data_func_params = {'time': ('2017-03-01', '2017-06-28')}\n",
    "\n",
    "# Extract training data for each training shapefile and train classifier\n",
    "classifier, _, _ = randomforest_train(train_shps = train_shps,\n",
    "                                      train_field = \"class\",\n",
    "                                      data_func = tc_import, #   hltc_import,\n",
    "                                      data_func_params = data_func_params,\n",
    "                                      classifier_params = classifier_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import analysis data and classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ls8_nbart_albers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:47: FutureWarning: casting an xarray.Dataset to a boolean will change in xarray v0.11 to only include data variables, not coordinates. Cast the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ls8_nbart_albers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:58: FutureWarning: casting an xarray.Dataset to a boolean will change in xarray v0.11 to only include data variables, not coordinates. Cast the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making mask ls8_pq_albers\n",
      "Masked ls8_nbart_albers with ls8_pq_albers and filtered terrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:93: FutureWarning: calling len() on an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Call len() on the Dataset.variables property instead, like ``len(ds.variables)``, to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data to classify:\n",
      "Rows: 1601\n",
      "Columns: 1601\n",
      "Bands: 3\n",
      "Classification running...\n",
      "  Classification complete\n",
      "  0 nodata cells removed\n",
      "    Classification exported\n"
     ]
    }
   ],
   "source": [
    "# Set up analysis data query\n",
    "lat_point, lon_point, buffer = -12.5615704994, 135.013735867, 20000\n",
    "x, y = geometry.point(lon_point, lat_point, CRS('WGS84')).to_crs(CRS('EPSG:3577')).points[0]\n",
    "query = {'x': (x - buffer, x + buffer),\n",
    "         'y': (y - buffer, y + buffer),\n",
    "         'time': ('2017-03-01', '2017-06-28'),\n",
    "         'crs': 'EPSG:3577'}\n",
    "\n",
    "# Load data from datacube\n",
    "analysis_xarray = tc_import(query)\n",
    "# analysis_xarray = hltc_import(query)\n",
    "\n",
    "# Run classification and export to file   \n",
    "randomforest_classify(classifier = classifier,\n",
    "                      analysis_data = analysis_xarray,\n",
    "                      classification_output = classification_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export tree diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot output random forest trees to file\n",
    "for n, tree_in_forest in enumerate(classifier.estimators_):\n",
    "\n",
    "    # Create graph and save to dot file\n",
    "    export_graphviz(tree_in_forest,\n",
    "                    out_file = \"figures/tree_graphs/tree.dot\",\n",
    "                    feature_names = list(analysis_xarray.data_vars),\n",
    "                    class_names = classification_names,\n",
    "                    filled = True,\n",
    "                    rounded = True)\n",
    "\n",
    "    # Plot as figure\n",
    "    os.system('dot -Tpng figures/tree_graphs/tree.dot -o ' + \\\n",
    "              'figures/tree_graphs/tree' + str(n + 1) + '.png')    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Plot performance of model by parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing training data from raw_data/train/training_data_tasseledcap.shp using query:\n",
      "{'x': (352998.0302334339, 313256.0191187404), 'y': (-1317049.5107177817, -1347981.8454887671), 'crs': 'EPSG:3577', 'time': ('2017-03-01', '2017-06-28')}\n",
      "Loading ls8_nbart_albers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:47: FutureWarning: casting an xarray.Dataset to a boolean will change in xarray v0.11 to only include data variables, not coordinates. Cast the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ls8_nbart_albers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:58: FutureWarning: casting an xarray.Dataset to a boolean will change in xarray v0.11 to only include data variables, not coordinates. Cast the Dataset.variables property instead to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making mask ls8_pq_albers\n",
      "Masked ls8_nbart_albers with ls8_pq_albers and filtered terrain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/ipykernel_launcher.py:93: FutureWarning: calling len() on an xarray.Dataset will change in xarray v0.11 to only include data variables, not coordinates. Call len() on the Dataset.variables property instead, like ``len(ds.variables)``, to preserve existing behavior in a forwards compatible manner.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training random forest classifier...\n",
      "Model trained on 3 bands and 71 training samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/g/data/v10/public/modules/agdc-py3-env/20171214/envs/agdc/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7418f3e978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "# support for parallelized ensembles but is necessary for tracking the OOB\n",
    "# error trajectory during training.\n",
    "\n",
    "# Extract training data\n",
    "_, train_lab, train_samp = randomforest_train(train_shps = train_shps,\n",
    "                                              train_field = \"class\",\n",
    "                                              data_func = tc_import, #   hltc_import,\n",
    "                                              data_func_params = data_func_params,\n",
    "                                              classifier_params = classifier_params)\n",
    "\n",
    "# Test effect of max features\n",
    "classifier_scenario = [(\"max_features = 'sqrt'\",\n",
    "                        RandomForestClassifier(warm_start = True,\n",
    "                                               oob_score = True,\n",
    "                                               max_features = \"sqrt\")),\n",
    "                       (\"max_features = 'log2'\",\n",
    "                      RandomForestClassifier(warm_start = True, \n",
    "                                             oob_score = True,\n",
    "                                             max_features = \"log2\")),\n",
    "                       (\"max_features = '0.5'\",\n",
    "                        RandomForestClassifier(warm_start = True, \n",
    "                                               max_features = 0.5,\n",
    "                                               oob_score = True)),\n",
    "                       (\"max_features = None\",\n",
    "                        RandomForestClassifier(warm_start = True,\n",
    "                                               max_features = None,\n",
    "                                               oob_score = True))]\n",
    "\n",
    "# Test effect of minimum samples per leaf\n",
    "classifier_scenario = [(\"Leaf = 1\",\n",
    "                      RandomForestClassifier(warm_start = True, \n",
    "                                             min_samples_leaf = 1,\n",
    "                                             oob_score = True)),                       \n",
    "                       (\"Leaf = 5\",\n",
    "                        RandomForestClassifier(warm_start = True,\n",
    "                                               min_samples_leaf = 5,\n",
    "                                               oob_score = True)),                       \n",
    "                       (\"Leaf = 20\",\n",
    "                        RandomForestClassifier(warm_start = True, \n",
    "                                               min_samples_leaf = 20,\n",
    "                                               oob_score = True))]\n",
    "\n",
    "# Test effect of max depth\n",
    "classifier_scenario = [(\"Max depth = 5\",\n",
    "                      RandomForestClassifier(warm_start = True,\n",
    "                                             max_depth = 5,\n",
    "                                             oob_score = True)),                       \n",
    "                       (\"Max depth = 10\",\n",
    "                        RandomForestClassifier(warm_start = True,\n",
    "                                               max_depth = 10,\n",
    "                                               oob_score = True)),                       \n",
    "                       (\"Max depth = 20\",\n",
    "                        RandomForestClassifier(warm_start = True, \n",
    "                                               max_depth = 20,\n",
    "                                               oob_score = True))]\n",
    "\n",
    "# Test effect of max depth\n",
    "classifier_scenario = [(\"Max depth = 5\",\n",
    "                      RandomForestClassifier(warm_start = True,\n",
    "                                             max_depth = 5,\n",
    "                                             oob_score = True)),                       \n",
    "                       (\"Max depth = 10\",\n",
    "                        RandomForestClassifier(warm_start = True,\n",
    "                                               max_depth = 10,\n",
    "                                               oob_score = True)),                       \n",
    "                       (\"Max depth = 20\",\n",
    "                        RandomForestClassifier(warm_start = True, \n",
    "                                               max_depth = 20,\n",
    "                                               oob_score = True))]\n",
    "\n",
    "# Plot OOB error by classifier scenario\n",
    "randomforest_eval(training_labels = train_lab, \n",
    "                  training_samples = train_samp, \n",
    "                  classifier_scenario = classifier_scenario,\n",
    "                  output_path = \"figures/random_forest_params.png\",\n",
    "                  max_estimators = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification statistics (TBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verification data\n",
    "# shapefiles = glob.glob(validation_data_path + \"/*.shp\")\n",
    "# classes = [i.split(\"/\")[2][0:1] for i in shapefiles]\n",
    "# verification_pixels = vectors_to_raster(shapefiles, rows, cols, geo_transform, proj)\n",
    "# for_verification = np.nonzero(verification_pixels)\n",
    "# verification_labels = verification_pixels[for_verification]\n",
    "# predicted_labels = classification[for_verification]\n",
    "\n",
    "# # Confusion matrix\n",
    "# print(\"Confussion matrix:\\n%s\" %\n",
    "#       metrics.confusion_matrix(verification_labels, predicted_labels))\n",
    "# target_names = ['Class %s' % s for s in classes]\n",
    "\n",
    "# # Per class report\n",
    "# print(\"Classification report:\\n%s\" %\n",
    "#       metrics.classification_report(verification_labels, predicted_labels,\n",
    "#                                     target_names=target_names))\n",
    "\n",
    "# # Overall classification accuracy\n",
    "# print(\"Classification accuracy: %f\" %\n",
    "#       metrics.accuracy_score(verification_labels, predicted_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
